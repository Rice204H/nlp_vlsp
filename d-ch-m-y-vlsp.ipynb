{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14093038,"sourceType":"datasetVersion","datasetId":8974101}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:55:14.609209Z","iopub.execute_input":"2025-12-12T02:55:14.609720Z","iopub.status.idle":"2025-12-12T02:55:14.617064Z","shell.execute_reply.started":"2025-12-12T02:55:14.609687Z","shell.execute_reply":"2025-12-12T02:55:14.616297Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/entovinlp/tst2012.vi\n/kaggle/input/entovinlp/train.vi\n/kaggle/input/entovinlp/tst2013.en\n/kaggle/input/entovinlp/tst2013.vi\n/kaggle/input/entovinlp/tst2012.en\n/kaggle/input/entovinlp/train.en\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# --- CELL 1: SETUP ---\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport tqdm\nimport warnings\n\n# C√†i ƒë·∫∑t th∆∞ vi·ªán tokenizers n·∫øu ch∆∞a c√≥\ntry:\n    import tokenizers\nexcept ImportError:\n    os.system('pip install tokenizers')\n    import tokenizers\n\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n\n# C·∫•u h√¨nh thi·∫øt b·ªã v√† Random Seed\nwarnings.filterwarnings(\"ignore\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"üîπ ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã: {device}\")\n\nSEED = 42\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:55:14.618622Z","iopub.execute_input":"2025-12-12T02:55:14.618918Z","iopub.status.idle":"2025-12-12T02:55:14.641334Z","shell.execute_reply.started":"2025-12-12T02:55:14.618895Z","shell.execute_reply":"2025-12-12T02:55:14.640620Z"}},"outputs":[{"name":"stdout","text":"üîπ ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã: cuda\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import re\nimport html\nimport unicodedata\n\"\"\"\n    H√†m l√†m s·∫°ch c∆° b·∫£n, d√πng CHUNG cho c·∫£ train.vi, train.en v√† c√¢u input khi d·ªãch.\n    M·ª•c ti√™u:\n      - B·ªè kho·∫£ng tr·∫Øng th·ª´a, k√Ω t·ª± v√¥ h√¨nh\n      - Gi·∫£i m√£ HTML (&quot; -> \")\n      - Chu·∫©n h√≥a Unicode NFC (d·∫•u ti·∫øng Vi·ªát)\n      - √âp v·ªÅ ch·ªØ th∆∞·ªùng (r·∫•t quan tr·ªçng v√¨ Field(lower=True))\n      - Chu·∫©n h√≥a d·∫•u c√¢u: t√°ch , . ! ? ; : () \" ' ra kh·ªèi t·ª´\n    \"\"\"\ndef clean_text(text: str) -> str:\n    if not isinstance(text, str):\n        return \"\"\n\n    text = text.strip()\n    text = unicodedata.normalize(\"NFC\", text)\n    text = text.lower()\n    text = re.sub(r\"<[^>]+>\", \" \", text)\n    if not text:\n        return \"\"\n\n    # 1. Gi·∫£i m√£ html\n    text = html.unescape(text)\n\n    # 2. Expand contraction (nh∆∞ anh ƒë√£ vi·∫øt)\n    split_patterns = [\n        # BE (am/is/are)\n        (r\"\\bi\\s*m\\b\", \"i am\"),\n        (r\"\\byou\\s*re\\b\", \"you are\"),\n        (r\"\\bwe\\s*re\\b\", \"we are\"),\n        (r\"\\bthey\\s*re\\b\", \"they are\"),\n        (r\"\\bhe\\s*s\\b\", \"he is\"),\n        (r\"\\bshe\\s*s\\b\", \"she is\"),\n        (r\"\\bit\\s*s\\b\", \"it is\"),\n        (r\"\\bthat\\s*s\\b\", \"that is\"),\n        (r\"\\bthere\\s*s\\b\", \"there is\"),\n        (r\"\\bhere\\s*s\\b\", \"here is\"),\n    \n        # HAVE\n        (r\"\\bi\\s*ve\\b\", \"i have\"),\n        (r\"\\byou\\s*ve\\b\", \"you have\"),\n        (r\"\\bwe\\s*ve\\b\", \"we have\"),\n        (r\"\\bthey\\s*ve\\b\", \"they have\"),\n    \n        # WILL\n        (r\"\\bi\\s*ll\\b\", \"i will\"),\n        (r\"\\byou\\s*ll\\b\", \"you will\"),\n        (r\"\\bwe\\s*ll\\b\", \"we will\"),\n        (r\"\\bthey\\s*ll\\b\", \"they will\"),\n        (r\"\\bhe\\s*ll\\b\", \"he will\"),\n        (r\"\\bshe\\s*ll\\b\", \"she will\"),\n        (r\"\\bit\\s*ll\\b\", \"it will\"),\n    \n        # WOULD\n        (r\"\\bi\\s*d\\b\", \"i would\"),\n        (r\"\\byou\\s*d\\b\", \"you would\"),\n        (r\"\\bwe\\s*d\\b\", \"we would\"),\n        (r\"\\bthey\\s*d\\b\", \"they would\"),\n        (r\"\\bhe\\s*d\\b\", \"he would\"),\n        (r\"\\bshe\\s*d\\b\", \"she would\"),\n        (r\"\\bit\\s*d\\b\", \"it would\"),\n        (r\"\\bthat\\s*d\\b\", \"that would\"),\n    \n        # NOT (full)\n        (r\"\\bdon\\s*t\\b\", \"do not\"),\n        (r\"\\bdoesn\\s*t\\b\", \"does not\"),\n        (r\"\\bdidn\\s*t\\b\", \"did not\"),\n        (r\"\\bcan\\s*t\\b\", \"can not\"),\n        (r\"\\bcouldn\\s*t\\b\", \"could not\"),\n        (r\"\\bshouldn\\s*t\\b\", \"should not\"),\n        (r\"\\bwouldn\\s*t\\b\", \"would not\"),\n        (r\"\\bisn\\s*t\\b\", \"is not\"),\n        (r\"\\baren\\s*t\\b\", \"are not\"),\n        (r\"\\bwasn\\s*t\\b\", \"was not\"),\n        (r\"\\bweren\\s*t\\b\", \"were not\"),\n        (r\"\\bwon\\s*t\\b\", \"will not\"),\n        (r\"\\bmustn\\s*t\\b\", \"must not\"),\n        (r\"\\bneedn\\s*t\\b\", \"need not\"),\n        (r\"\\bmightn\\s*t\\b\", \"might not\"),\n    \n        # OTHER\n        (r\"\\blet\\s*s\\b\", \"let us\"),\n    ]\n\n    for pat, repl in split_patterns:\n        text = re.sub(pat, repl, text)\n\n    full_patterns = [\n        # BE\n        (r\"\\bi m\\b\", \"i am\"),\n        (r\"\\byou re\\b\", \"you are\"),\n        (r\"\\bwe re\\b\", \"we are\"),\n        (r\"\\bthey re\\b\", \"they are\"),\n        (r\"\\bhe s\\b\", \"he is\"),\n        (r\"\\bshe s\\b\", \"she is\"),\n        (r\"\\bit s\\b\", \"it is\"),\n        (r\"\\bthat s\\b\", \"that is\"),\n        (r\"\\bhere s\\b\", \"here is\"),\n        (r\"\\bthere s\\b\", \"there is\"),\n    \n        # HAVE\n        (r\"\\bi ve\\b\", \"i have\"),\n        (r\"\\byou ve\\b\", \"you have\"),\n        (r\"\\bwe ve\\b\", \"we have\"),\n        (r\"\\bthey ve\\b\", \"they have\"),\n\n        # WILL\n        (r\"\\bi ll\\b\", \"I will\"),\n        (r\"\\byou ll\\b\", \"You will\"),\n        (r\"\\bwe ll\\b\", \"We will\"),\n        (r\"\\bthey ll\\b\", \"They will\"),\n        (r\"\\bhe ll\\b\", \"He will\"),\n        (r\"\\bshe ll\\b\", \"She will\"),\n        (r\"\\bit ll\\b\", \"It will\"),\n    \n        # WOULD\n        (r\"\\bi d\\b\", \"I would\"),\n        (r\"\\byou d\\b\", \"You would\"),\n        (r\"\\bwe d\\b\", \"We would\"),\n        (r\"\\bthey d\\b\", \"They would\"),\n        (r\"\\bhe d\\b\", \"He would\"),\n        (r\"\\bshe d\\b\", \"She would\"),\n        (r\"\\bit d\\b\", \"It would\"),\n        (r\"\\bthat d\\b\", \"That would\"),\n    \n        # NOT\n        (r\"\\bdon t\\b\", \"do not\"),\n        (r\"\\bdoesn t\\b\", \"does not\"),\n        (r\"\\bdidn t\\b\", \"did not\"),\n        (r\"\\bcan t\\b\", \"can not\"),\n        (r\"\\bcouldn t\\b\", \"could not\"),\n        (r\"\\bshouldn t\\b\", \"should not\"),\n        (r\"\\bwouldn t\\b\", \"would not\"),\n        (r\"\\bisn t\\b\", \"is not\"),\n        (r\"\\baren t\\b\", \"are not\"),\n        (r\"\\bwasn t\\b\", \"was not\"),\n        (r\"\\bweren t\\b\", \"were not\"),\n        (r\"\\bwon t\\b\", \"will not\"),\n        (r\"\\bmustn t\\b\", \"must not\"),\n        (r\"\\bneedn t\\b\", \"need not\"),\n        (r\"\\bmightn t\\b\", \"might not\"),\n    \n        # OTHER\n        (r\"\\blet s\\b\", \"let us\"),\n    ]\n\n    for pat, repl in full_patterns:\n        text = re.sub(pat, repl, text)\n\n    # 3. B·ªè k√Ω t·ª± v√¥ h√¨nh + b·ªè --, ---, ...\n    text = text.replace(\"\\u200b\", \"\")\n    text = re.sub(r\"-{2,}\", \" \", text)\n\n    # 4. G·ªôp nhi·ªÅu space li√™n ti·∫øp\n    text = re.sub(r\"\\s+\", \" \", text)\n    \n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:55:14.642119Z","iopub.execute_input":"2025-12-12T02:55:14.642303Z","iopub.status.idle":"2025-12-12T02:55:14.659718Z","shell.execute_reply.started":"2025-12-12T02:55:14.642289Z","shell.execute_reply":"2025-12-12T02:55:14.658886Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# --- CELL 2: DATA READING FUNCTION ---\ndef read_parallel_files(src_filename, tgt_filename):\n    \"\"\"ƒê·ªçc c·∫∑p file song ng·ªØ, tr·∫£ v·ªÅ list c√°c tuple (c√¢u_ngu·ªìn, c√¢u_ƒë√≠ch)\"\"\"\n    # Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n (h·ªó tr·ª£ c·∫£ th∆∞ m·ª•c hi·ªán t·∫°i v√† th∆∞ m·ª•c input c·ªßa Kaggle)\n    possible_paths = [\"./\", \"/kaggle/input/\", \"/kaggle/working/\"]\n    \n    src_path, tgt_path = None, None\n    for p in possible_paths:\n        if os.path.exists(os.path.join(p, src_filename)):\n            src_path = os.path.join(p, src_filename)\n        if os.path.exists(os.path.join(p, tgt_filename)):\n            tgt_path = os.path.join(p, tgt_filename)\n            \n    if not src_path or not tgt_path:\n        print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file {src_filename} ho·∫∑c {tgt_filename}. B·ªè qua.\")\n        return []\n\n    print(f\"üìñ ƒêang ƒë·ªçc: {src_path} v√† {tgt_path}\")\n    with open(src_path, 'r', encoding='utf-8') as f_src, \\\n         open(tgt_path, 'r', encoding='utf-8') as f_tgt:\n        src_lines = [clean_text(line.strip()) for line in f_src.read().splitlines()]\n        tgt_lines = [clean_text(line.strip()) for line in f_tgt.read().splitlines()]\n    \n    # L·ªçc b·ªè c√°c c·∫∑p c√¢u r·ªóng ho·∫∑c l·ªách d√≤ng\n    pairs = []\n    min_len = min(len(src_lines), len(tgt_lines))\n    for i in range(min_len):\n        if src_lines[i] and tgt_lines[i]:\n            pairs.append((src_lines[i], tgt_lines[i]))\n            \n    return pairs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:55:14.660417Z","iopub.execute_input":"2025-12-12T02:55:14.660652Z","iopub.status.idle":"2025-12-12T02:55:14.677940Z","shell.execute_reply.started":"2025-12-12T02:55:14.660632Z","shell.execute_reply":"2025-12-12T02:55:14.677244Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# --- CELL 3: LOAD DATA ---\nprint(\"\\n--- ƒêANG T·∫¢I D·ªÆ LI·ªÜU ---\")\n# ƒê·∫£m b·∫£o t√™n file kh·ªõp v·ªõi file b·∫°n upload\ntrain_pairs = read_parallel_files(\"/kaggle/input/entovinlp/train.en\", \"/kaggle/input/entovinlp/train.vi\")\nval_pairs = read_parallel_files(\"/kaggle/input/entovinlp/tst2012.en\", \"/kaggle/input/entovinlp/tst2012.vi\")\ntest_pairs = read_parallel_files(\"/kaggle/input/entovinlp/tst2013.en\", \"/kaggle/input/entovinlp/tst2013.vi\")\n\nprint(f\"‚úÖ Train size: {len(train_pairs)}\")\nprint(f\"‚úÖ Val size: {len(val_pairs)}\")\nprint(f\"‚úÖ Test size: {len(test_pairs)}\")\n\nif len(train_pairs) > 0:\n    print(f\"üîé V√≠ d·ª• m·∫´u: {train_pairs[0:5]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:55:14.759388Z","iopub.execute_input":"2025-12-12T02:55:14.759671Z","iopub.status.idle":"2025-12-12T02:56:16.270956Z","shell.execute_reply.started":"2025-12-12T02:55:14.759651Z","shell.execute_reply":"2025-12-12T02:56:16.270215Z"}},"outputs":[{"name":"stdout","text":"\n--- ƒêANG T·∫¢I D·ªÆ LI·ªÜU ---\nüìñ ƒêang ƒë·ªçc: /kaggle/input/entovinlp/train.en v√† /kaggle/input/entovinlp/train.vi\nüìñ ƒêang ƒë·ªçc: /kaggle/input/entovinlp/tst2012.en v√† /kaggle/input/entovinlp/tst2012.vi\nüìñ ƒêang ƒë·ªçc: /kaggle/input/entovinlp/tst2013.en v√† /kaggle/input/entovinlp/tst2013.vi\n‚úÖ Train size: 133166\n‚úÖ Val size: 1553\n‚úÖ Test size: 1268\nüîé V√≠ d·ª• m·∫´u: [('rachel pike : the science behind a climate headline', 'khoa h·ªçc ƒë·∫±ng sau m·ªôt ti√™u ƒë·ªÅ v·ªÅ kh√≠ h·∫≠u'), ('in 4 minutes , atmospheric chemist rachel pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team one of thousands who contributed taking a risky flight over the rainforest in pursuit of data on a key molecule .', 'trong 4 ph√∫t , chuy√™n gia ho√° h·ªçc kh√≠ quy·ªÉn rachel pike gi·ªõi thi·ªáu s∆° l∆∞·ª£c v·ªÅ nh·ªØng n·ªó l·ª±c khoa h·ªçc mi·ªát m√†i ƒë·∫±ng sau nh·ªØng ti√™u ƒë·ªÅ t√°o b·∫°o v·ªÅ bi·∫øn ƒë·ªïi kh√≠ h·∫≠u , c√πng v·ªõi ƒëo√†n nghi√™n c·ª©u c·ªßa m√¨nh h√†ng ng√†n ng∆∞·ªùi ƒë√£ c·ªëng hi·∫øn cho d·ª± √°n n√†y m·ªôt chuy·∫øn bay m·∫°o hi·ªÉm qua r·ª´ng gi√† ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin v·ªÅ m·ªôt ph√¢n t·ª≠ then ch·ªët .'), (\"i 'd like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\", 't√¥i mu·ªën cho c√°c b·∫°n bi·∫øt v·ªÅ s·ª± to l·ªõn c·ªßa nh·ªØng n·ªó l·ª±c khoa h·ªçc ƒë√£ g√≥p ph·∫ßn l√†m n√™n c√°c d√≤ng t√≠t b·∫°n th∆∞·ªùng th·∫•y tr√™n b√°o .'), ('headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .', 'c√≥ nh·ªØng d√≤ng tr√¥ng nh∆∞ th·∫ø n√†y khi b√†n v·ªÅ bi·∫øn ƒë·ªïi kh√≠ h·∫≠u , v√† nh∆∞ th·∫ø n√†y khi n√≥i v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ hay kh√≥i b·ª•i .'), ('they are both two branches of the same field of atmospheric science .', 'c·∫£ hai ƒë·ªÅu l√† m·ªôt nh√°nh c·ªßa c√πng m·ªôt lƒ©nh v·ª±c trong ng√†nh khoa h·ªçc kh√≠ quy·ªÉn .')]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# --- CELL 4: TRAIN TOKENIZERS ---\nprint(\"\\n--- HU·∫§N LUY·ªÜN TOKENIZER ---\")\n\ndef train_bpe_tokenizer(texts, vocab_size=8000):\n    tokenizer = Tokenizer(models.BPE())\n    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n    tokenizer.decoder = decoders.ByteLevel()\n    \n    trainer = trainers.BpeTrainer(\n        vocab_size=vocab_size,\n        special_tokens=[\"[PAD]\", \"[START]\", \"[END]\", \"[UNK]\"],\n        show_progress=False\n    )\n    tokenizer.train_from_iterator(texts, trainer=trainer)\n    return tokenizer\n\n# G·ªôp text ƒë·ªÉ train tokenizer\nall_src_text = [p[0] for p in train_pairs + val_pairs]\nall_tgt_text = [p[1] for p in train_pairs + val_pairs]\n\nif not all_src_text: # Dummy data n·∫øu ch∆∞a load ƒë∆∞·ª£c file\n    all_src_text = [\"Hello world\"]\n    all_tgt_text = [\"Xin ch√†o\"]\n\nen_tokenizer = train_bpe_tokenizer(all_src_text, vocab_size=10000)\nvi_tokenizer = train_bpe_tokenizer(all_tgt_text, vocab_size=10000)\n\n# L·∫•y ID c√°c token ƒë·∫∑c bi·ªát\nPAD_ID = en_tokenizer.token_to_id(\"[PAD]\")\nSTART_ID = vi_tokenizer.token_to_id(\"[START]\")\nEND_ID = vi_tokenizer.token_to_id(\"[END]\")\n\nprint(\"‚úÖ Tokenizer ƒë√£ s·∫µn s√†ng.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:56:16.272462Z","iopub.execute_input":"2025-12-12T02:56:16.272724Z","iopub.status.idle":"2025-12-12T02:56:22.699004Z","shell.execute_reply.started":"2025-12-12T02:56:16.272707Z","shell.execute_reply":"2025-12-12T02:56:22.698117Z"}},"outputs":[{"name":"stdout","text":"\n--- HU·∫§N LUY·ªÜN TOKENIZER ---\n‚úÖ Tokenizer ƒë√£ s·∫µn s√†ng.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# --- CELL 5: DATASET CLASS ---\nclass EnViDataset(Dataset):\n    def __init__(self, pairs):\n        self.pairs = pairs\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        return self.pairs[idx]\n\ndef collate_fn(batch):\n    en_batch, vi_batch = zip(*batch)\n    \n    # Encode ti·∫øng Anh (Source)\n    en_enc = en_tokenizer.encode_batch(list(en_batch))\n    en_ids = [e.ids for e in en_enc]\n    \n    # Encode ti·∫øng Vi·ªát (Target) - Th√™m START v√† END th·ªß c√¥ng\n    vi_ids = []\n    for text in vi_batch:\n        ids = vi_tokenizer.encode(text).ids\n        vi_ids.append([START_ID] + ids + [END_ID])\n    \n    # Padding\n    max_len_en = max([len(x) for x in en_ids])\n    max_len_vi = max([len(x) for x in vi_ids])\n    \n    padded_en = [x + [PAD_ID] * (max_len_en - len(x)) for x in en_ids]\n    padded_vi = [x + [PAD_ID] * (max_len_vi - len(x)) for x in vi_ids]\n    \n    return torch.tensor(padded_en), torch.tensor(padded_vi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:56:22.699969Z","iopub.execute_input":"2025-12-12T02:56:22.700239Z","iopub.status.idle":"2025-12-12T02:56:22.706943Z","shell.execute_reply.started":"2025-12-12T02:56:22.700213Z","shell.execute_reply":"2025-12-12T02:56:22.706156Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# --- CELL 6: DATALOADERS ---\nBATCH_SIZE = 32\n\ntrain_loader = DataLoader(EnViDataset(train_pairs), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(EnViDataset(val_pairs), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n\nprint(f\"DataLoaders created. Batch size: {BATCH_SIZE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:56:22.707778Z","iopub.execute_input":"2025-12-12T02:56:22.708044Z","iopub.status.idle":"2025-12-12T02:56:22.728961Z","shell.execute_reply.started":"2025-12-12T02:56:22.708016Z","shell.execute_reply":"2025-12-12T02:56:22.728082Z"}},"outputs":[{"name":"stdout","text":"DataLoaders created. Batch size: 32\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# --- CELL 7: MODEL COMPONENTS ---\n# --- Rotary Positional Embeddings ---\ndef rotate_half(x):\n    x1, x2 = x.chunk(2, dim=-1)\n    return torch.cat((-x2, x1), dim=-1)\n\ndef apply_rotary_pos_emb(x, cos, sin):\n    return (x * cos) + (rotate_half(x) * sin)\n\nclass RotaryPositionalEncoding(nn.Module):\n    def __init__(self, head_dim, max_seq_len=2048):\n        super().__init__()\n        inv_freq = 1.0 / (10000 ** (torch.arange(0, head_dim, 2).float() / head_dim))\n        t = torch.arange(max_seq_len).float()\n        freqs = torch.outer(t, inv_freq)\n        emb = torch.cat((freqs, freqs), dim=-1)\n        self.register_buffer(\"cos\", emb.cos()[None, :, None, :])\n        self.register_buffer(\"sin\", emb.sin()[None, :, None, :])\n\n    def forward(self, x, seq_len):\n        return self.cos[:, :seq_len, :, :], self.sin[:, :seq_len, :, :]\n\n# --- Feed Forward (SwiGLU) ---\nclass SwiGLU(nn.Module):\n    def __init__(self, hidden_dim, intermediate_dim):\n        super().__init__()\n        self.w1 = nn.Linear(hidden_dim, intermediate_dim)\n        self.w2 = nn.Linear(hidden_dim, intermediate_dim)\n        self.w3 = nn.Linear(intermediate_dim, hidden_dim)\n\n    def forward(self, x):\n        return self.w3(F.silu(self.w1(x)) * self.w2(x))\n\n# --- GQA Attention ---\nclass GQA(nn.Module):\n    def __init__(self, hidden_dim, num_heads, num_kv_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.num_kv_heads = num_kv_heads\n        self.head_dim = hidden_dim // num_heads\n        self.num_groups = num_heads // num_kv_heads\n        \n        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n        self.k_proj = nn.Linear(hidden_dim, num_kv_heads * self.head_dim)\n        self.v_proj = nn.Linear(hidden_dim, num_kv_heads * self.head_dim)\n        self.o_proj = nn.Linear(hidden_dim, hidden_dim)\n        self.dropout = dropout\n\n    def forward(self, x, enc_out=None, mask=None, rope_cos=None, rope_sin=None):\n        batch, seq_len, _ = x.shape\n        kv_input = enc_out if enc_out is not None else x\n        kv_seq_len = kv_input.shape[1]\n\n        q = self.q_proj(x).view(batch, seq_len, self.num_heads, self.head_dim)\n        k = self.k_proj(kv_input).view(batch, kv_seq_len, self.num_kv_heads, self.head_dim)\n        v = self.v_proj(kv_input).view(batch, kv_seq_len, self.num_kv_heads, self.head_dim)\n\n        if rope_cos is not None and enc_out is None:\n            q = apply_rotary_pos_emb(q, rope_cos, rope_sin)\n            k = apply_rotary_pos_emb(k, rope_cos, rope_sin)\n\n        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n\n        if self.num_groups > 1:\n            k = k[:, :, None, :, :].expand(batch, self.num_kv_heads, self.num_groups, kv_seq_len, self.head_dim).reshape(batch, self.num_heads, kv_seq_len, self.head_dim)\n            v = v[:, :, None, :, :].expand(batch, self.num_kv_heads, self.num_groups, kv_seq_len, self.head_dim).reshape(batch, self.num_heads, kv_seq_len, self.head_dim)\n\n        out = F.scaled_dot_product_attention(q, k, v, attn_mask=mask, dropout_p=self.dropout if self.training else 0.0)\n        return self.o_proj(out.transpose(1, 2).reshape(batch, seq_len, -1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:56:22.730560Z","iopub.execute_input":"2025-12-12T02:56:22.730877Z","iopub.status.idle":"2025-12-12T02:56:22.752385Z","shell.execute_reply.started":"2025-12-12T02:56:22.730860Z","shell.execute_reply":"2025-12-12T02:56:22.751584Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# --- CELL 8: TRANSFORMER MODEL ---\nclass TransformerBlock(nn.Module):\n    def __init__(self, hidden_dim, num_heads, num_kv_heads, dropout=0.1, is_decoder=False):\n        super().__init__()\n        self.norm1 = nn.RMSNorm(hidden_dim)\n        self.attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n        self.is_decoder = is_decoder\n        if is_decoder:\n            self.norm2 = nn.RMSNorm(hidden_dim)\n            self.cross_attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n        self.norm_ffn = nn.RMSNorm(hidden_dim)\n        self.ffn = SwiGLU(hidden_dim, hidden_dim * 4)\n\n    def forward(self, x, enc_out=None, mask=None, cross_mask=None, rope_cos=None, rope_sin=None):\n        x = x + self.attn(self.norm1(x), mask=mask, rope_cos=rope_cos, rope_sin=rope_sin)\n        if self.is_decoder:\n            x = x + self.cross_attn(self.norm2(x), enc_out=enc_out, mask=cross_mask)\n        x = x + self.ffn(self.norm_ffn(x))\n        return x\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab, tgt_vocab, hidden_dim=256, num_layers=4, num_heads=8, num_kv_heads=4):\n        super().__init__()\n        self.src_emb = nn.Embedding(src_vocab, hidden_dim)\n        self.tgt_emb = nn.Embedding(tgt_vocab, hidden_dim)\n        self.rope = RotaryPositionalEncoding(hidden_dim // num_heads)\n        self.encoders = nn.ModuleList([TransformerBlock(hidden_dim, num_heads, num_kv_heads) for _ in range(num_layers)])\n        self.decoders = nn.ModuleList([TransformerBlock(hidden_dim, num_heads, num_kv_heads, is_decoder=True) for _ in range(num_layers)])\n        self.final_norm = nn.RMSNorm(hidden_dim)\n        self.fc_out = nn.Linear(hidden_dim, tgt_vocab)\n\n    def forward(self, src, tgt, src_mask, tgt_mask):\n        x = self.src_emb(src)\n        rope_cos, rope_sin = self.rope(x, x.shape[1])\n        for layer in self.encoders:\n            x = layer(x, mask=src_mask, rope_cos=rope_cos, rope_sin=rope_sin)\n        enc_out = x\n        \n        x = self.tgt_emb(tgt)\n        rope_cos_tgt, rope_sin_tgt = self.rope(x, x.shape[1])\n        for layer in self.decoders:\n            x = layer(x, enc_out=enc_out, mask=tgt_mask, cross_mask=src_mask, rope_cos=rope_cos_tgt, rope_sin=rope_sin_tgt)\n        return self.fc_out(self.final_norm(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:56:22.753952Z","iopub.execute_input":"2025-12-12T02:56:22.754835Z","iopub.status.idle":"2025-12-12T02:56:22.773910Z","shell.execute_reply.started":"2025-12-12T02:56:22.754811Z","shell.execute_reply":"2025-12-12T02:56:22.773351Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# --- CELL 9: INIT TRAINING ---\ndef create_masks(src, tgt):\n    src_mask = (src == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n    batch, seq_len = tgt.shape\n    causal = torch.triu(torch.full((seq_len, seq_len), float('-inf'), device=device), diagonal=1)\n    tgt_pad = (tgt == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n    return src_mask, causal + tgt_pad\n\nmodel = Transformer(\n    src_vocab=en_tokenizer.get_vocab_size(),\n    tgt_vocab=vi_tokenizer.get_vocab_size(),\n    hidden_dim=256, num_layers=4, num_heads=8, num_kv_heads=4\n).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_ID, label_smoothing=0.1)\noptimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.0001)\n\nprint(\"Model Initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:56:22.774637Z","iopub.execute_input":"2025-12-12T02:56:22.774954Z","iopub.status.idle":"2025-12-12T02:56:24.149831Z","shell.execute_reply.started":"2025-12-12T02:56:22.774929Z","shell.execute_reply":"2025-12-12T02:56:24.149068Z"}},"outputs":[{"name":"stdout","text":"Model Initialized.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# --- CELL 10: TRAINING LOOP ---\nEPOCHS = 10\nprint(\"\\n--- B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN ---\")\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n    pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n    \n    for src, tgt in pbar:\n        src, tgt = src.to(device), tgt.to(device)\n        tgt_input, tgt_real = tgt[:, :-1], tgt[:, 1:]\n        src_mask, tgt_mask = create_masks(src, tgt_input)\n        \n        optimizer.zero_grad()\n        output = model(src, tgt_input, src_mask, tgt_mask)\n        loss = criterion(output.reshape(-1, output.shape[-1]), tgt_real.reshape(-1))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        \n        train_loss += loss.item()\n        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n        \n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for src, tgt in val_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            tgt_input, tgt_real = tgt[:, :-1], tgt[:, 1:]\n            src_mask, tgt_mask = create_masks(src, tgt_input)\n            output = model(src, tgt_input, src_mask, tgt_mask)\n            val_loss += criterion(output.reshape(-1, output.shape[-1]), tgt_real.reshape(-1)).item()\n            \n    print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")\n\ntorch.save(model.state_dict(), \"transformer_en_vi.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:56:24.150600Z","iopub.execute_input":"2025-12-12T02:56:24.150980Z","iopub.status.idle":"2025-12-12T04:04:32.124558Z","shell.execute_reply.started":"2025-12-12T02:56:24.150957Z","shell.execute_reply":"2025-12-12T04:04:32.123706Z"}},"outputs":[{"name":"stdout","text":"\n--- B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:47<00:00, 10.22it/s, loss=3.7542]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 4.3289 | Val Loss: 3.7808\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:47<00:00, 10.21it/s, loss=3.3598]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 3.4575 | Val Loss: 3.5213\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:48<00:00, 10.18it/s, loss=3.0511]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 3.1961 | Val Loss: 3.4235\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:46<00:00, 10.24it/s, loss=2.9723]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 3.0395 | Val Loss: 3.3594\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:47<00:00, 10.22it/s, loss=2.9268]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 2.9232 | Val Loss: 3.3252\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:47<00:00, 10.22it/s, loss=2.8942]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 2.8285 | Val Loss: 3.3201\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:47<00:00, 10.21it/s, loss=2.6345]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 2.7475 | Val Loss: 3.3093\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:47<00:00, 10.21it/s, loss=2.5209]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 2.6762 | Val Loss: 3.3188\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:47<00:00, 10.21it/s, loss=2.5302]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 2.6128 | Val Loss: 3.3295\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4162/4162 [06:48<00:00, 10.19it/s, loss=2.7367]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 2.5550 | Val Loss: 3.3539\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# --- CELL 11: INFERENCE ---\nprint(\"\\n--- TEST K·∫æT QU·∫¢ ---\")\ndef translate(sentence, max_len=100):\n    model.eval()\n    with torch.no_grad():\n        src = torch.tensor([en_tokenizer.encode(sentence).ids]).to(device)\n        src_mask = (src == PAD_ID).unsqueeze(1).unsqueeze(2).float() * -1e9\n        tgt_ids = [START_ID]\n        \n        for _ in range(max_len):\n            tgt = torch.tensor([tgt_ids]).to(device)\n            causal = torch.triu(torch.full((tgt.shape[1], tgt.shape[1]), float('-inf'), device=device), diagonal=1)\n            out = model(src, tgt, src_mask, causal)\n            next_token = out[0, -1, :].argmax().item()\n            if next_token == END_ID: break\n            tgt_ids.append(next_token)\n        return vi_tokenizer.decode(tgt_ids[1:])\n\nfor i in range(5):\n    if len(test_pairs) > 0:\n        idx = random.randint(0, len(test_pairs)-1)\n        en_txt, vi_txt = test_pairs[idx]\n        print(f\"üîπ Input:  {en_txt}\\nüî∏ Target: {vi_txt}\\nüöÄ Model:  {translate(en_txt)}\\n{'-'*50}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:04:32.125579Z","iopub.execute_input":"2025-12-12T04:04:32.125859Z","iopub.status.idle":"2025-12-12T04:04:33.382988Z","shell.execute_reply.started":"2025-12-12T04:04:32.125830Z","shell.execute_reply":"2025-12-12T04:04:33.382199Z"}},"outputs":[{"name":"stdout","text":"\n--- TEST K·∫æT QU·∫¢ ---\nüîπ Input:  and he said that he needed those guns because of the trauma he 'd experienced as a young boy .\nüî∏ Target: v√† anh ta n√≥i r·∫±ng anh ta c·∫ßn nh·ªØng c√¢y s√∫ng n√†y b·ªüi v√¨ nh·ªØng t·ªïn th∆∞∆°ng m√† anh ƒë√£ tr·∫£i qua trong qu√° kh·ª© khi l√† m·ªôt ƒë·ª©a tr·∫ª .\nüöÄ Model:   v√† √¥ng ·∫•y n√≥i r·∫±ng √¥ng c·∫ßn nh·ªØng con s√∫ng ƒë√≥ v√¨ nh·ªØng ch·∫•n th∆∞∆°ng ƒë√≥ √¥ng ƒë√£ tr·∫£i qua khi c√≤n l√† m·ªôt c·∫≠u b√© .\n--------------------------------------------------\nüîπ Input:  am i south korean or north korean ?\nüî∏ Target: t√¥i l√† ng∆∞·ªùi nam tri·ªÅu ti√™n hay b·∫Øc tri·ªÅu ti√™n ?\nüöÄ Model:   t√¥i c√≥ ph·∫£i quay v·ªÅ nam h√†n hay b·∫Øc h√†n hay b·∫Øc h√†n ?\n--------------------------------------------------\nüîπ Input:  and so just as the womb entirely envelopes the embryo , which grows within it , the divine matrix of compassion nourishes the entire existence .\nüî∏ Target: v√† b·ªüi v√¨ t·ª≠ cung bao b·ªçc ho√†n to√†n ph√¥i thai ƒëang ph√°t tri·ªÉn trong l√≤ng n√≥ , ma tr·∫≠n thi√™ng li√™ng c·ªßa t√¨nh th∆∞∆°ng nu√¥i d∆∞·ª°ng to√†n b·ªô s·ª± s·ªëng ƒë√≥ .\nüöÄ Model:   v√† nh∆∞ l√† khi m√¥i tr∆∞·ªùng ho√†n to√†n b·ªã x√¢m chi·∫øm to√†n b·ªô qu√° tr√¨nh nh·∫≠n th·ª©c ƒë∆∞·ª£c sinh s·ªëng , v√† ph√°t tri·ªÉn b√™n trong n√≥ , ma tr·∫≠n c·ªßa l√≤ng t·ª´ bi c·ªßa l√≤ng t·ª´ bi , s·ª± t·ªìn t·∫°i c·ªßa c·∫£ s·ª± t·ªìn t·∫°i .\n--------------------------------------------------\nüîπ Input:  it 's really become sacred to us .\nüî∏ Target: n√≥ tr·ªü n√™n th·∫≠t thi√™ng li√™ng v·ªõi ch√∫ng t√¥i .\nüöÄ Model:   n√≥ th·ª±c s·ª± l√† m·ªôt th√†nh ng·ªØ .\n--------------------------------------------------\nüîπ Input:  this is a visualization of six months of my life .\nüî∏ Target: ƒë√¢y l√† nh·ªØng h√¨nh ·∫£nh tr·ª±c quan v·ªÅ cu·ªôc s·ªëng trong s√°u th√°ng ƒë√£ ƒë∆∞·ª£c ghi l·∫°i c·ªßa t√¥i .\nüöÄ Model:   ƒë√¢y l√† h√¨nh ·∫£nh c·ªßa 6 th√°ng ƒë·ªùi t√¥i .\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Test th·ªß c√¥ng 1 c√¢u ri√™ng\ncustom_sentence = \"I really like this model.\"\nprint(f\"\\nüöÄ Custom Test Input: {custom_sentence}\")\nprint(f\"‚úÖ Model Translation: {translate(custom_sentence)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:04:33.383796Z","iopub.execute_input":"2025-12-12T04:04:33.383983Z","iopub.status.idle":"2025-12-12T04:04:33.466867Z","shell.execute_reply.started":"2025-12-12T04:04:33.383968Z","shell.execute_reply":"2025-12-12T04:04:33.466304Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ Custom Test Input: I really like this model.\n‚úÖ Model Translation:  v√≠ d·ª• nh∆∞ m√¥ h√¨nh n√†y .\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:04:33.467626Z","iopub.execute_input":"2025-12-12T04:04:33.467834Z","iopub.status.idle":"2025-12-12T04:04:40.621574Z","shell.execute_reply.started":"2025-12-12T04:04:33.467818Z","shell.execute_reply":"2025-12-12T04:04:40.620810Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.11.3)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.2.0 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import sacrebleu\nimport random\nfrom tqdm import tqdm # Thanh hi·ªÉn th·ªã ti·∫øn ƒë·ªô\n\ndef calculate_bleu(data_pairs, num_samples=100):\n    print(f\"--- üìä ƒêANG T√çNH ƒêI·ªÇM BLEU TR√äN {num_samples} M·∫™U ---\")\n    \n    # Ch·ªçn ng·∫´u nhi√™n m·∫´u ƒë·ªÉ test (ho·∫∑c l·∫•y h·∫øt n·∫øu num_samples=None)\n    if num_samples is not None and num_samples < len(data_pairs):\n        samples = random.sample(data_pairs, num_samples)\n    else:\n        samples = data_pairs\n\n    preds = [] # C√°c c√¢u m√°y d·ªãch\n    refs = []  # C√°c c√¢u ƒë√°p √°n chu·∫©n\n\n    # B·∫Øt ƒë·∫ßu d·ªãch\n    for en_txt, vi_txt in tqdm(samples):\n        # D·ªãch c√¢u ti·∫øng Anh\n        pred_sent = translate(en_txt)\n        \n        preds.append(pred_sent)\n        refs.append(vi_txt) # Sacrebleu nh·∫≠n list c√°c string cho refs\n\n    # T√≠nh ƒëi·ªÉm BLEU\n    # refs c·∫ßn ƒë∆∞·ª£c b·ªçc trong list v√¨ 1 c√¢u input c√≥ th·ªÉ c√≥ nhi·ªÅu c√¢u target (·ªü ƒë√¢y ta c√≥ 1)\n    bleu = sacrebleu.corpus_bleu(preds, [refs])\n    \n    return bleu.score\n\n# --- CH·∫†Y T√çNH ƒêI·ªÇM ---\n# B·∫°n c√≥ th·ªÉ tƒÉng s·ªë l∆∞·ª£ng m·∫´u l√™n len(test_pairs) ƒë·ªÉ ch√≠nh x√°c h∆°n (s·∫Ω ch·∫°y l√¢u h∆°n)\nscore = calculate_bleu(test_pairs, num_samples=100)\n\nprint(f\"\\nüåü ƒêI·ªÇM BLEU C·ª¶A MODEL: {score:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:04:40.622541Z","iopub.execute_input":"2025-12-12T04:04:40.622841Z","iopub.status.idle":"2025-12-12T04:05:08.920607Z","shell.execute_reply.started":"2025-12-12T04:04:40.622805Z","shell.execute_reply":"2025-12-12T04:05:08.919937Z"}},"outputs":[{"name":"stdout","text":"--- üìä ƒêANG T√çNH ƒêI·ªÇM BLEU TR√äN 100 M·∫™U ---\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:28<00:00,  3.55it/s]","output_type":"stream"},{"name":"stdout","text":"\nüåü ƒêI·ªÇM BLEU C·ª¶A MODEL: 28.83\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":25}]}